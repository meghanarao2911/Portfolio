{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mghn_\\Desktop\\Imarticus_Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"C:/Users/mghn_/Desktop/Imarticus_Project\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mghn_\\Desktop\\Imarticus_Project\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv(\"TrainData_CSM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>...</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>default_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>150119</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81008.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.27</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>186161</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81008.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>150119</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81008.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  grade  sub_grade  emp_title  emp_length  \\\n",
       "0     5000.0     0     10.65      1         21     150119        10.0   \n",
       "1     2500.0     1     15.27      2         33     186161         0.5   \n",
       "2     2400.0     0     15.96      2         34     150119        10.0   \n",
       "\n",
       "   home_ownership  annual_inc  verification_status     ...       \\\n",
       "0               2     24000.0                    2     ...        \n",
       "1               2     30000.0                    1     ...        \n",
       "2               2     12252.0                    0     ...        \n",
       "\n",
       "  total_rec_late_fee  recoveries  last_pymnt_amnt  collections_12_mths_ex_med  \\\n",
       "0                0.0         0.0           171.62                         0.0   \n",
       "1                0.0         0.0           119.66                         0.0   \n",
       "2                0.0         0.0           649.91                         0.0   \n",
       "\n",
       "   policy_code  application_type  acc_now_delinq  tot_coll_amt  tot_cur_bal  \\\n",
       "0          1.0                 0             0.0           0.0      81008.5   \n",
       "1          1.0                 0             0.0           0.0      81008.5   \n",
       "2          1.0                 0             0.0           0.0      81008.5   \n",
       "\n",
       "   default_ind  \n",
       "0            0  \n",
       "1            1  \n",
       "2            0  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"issue_d\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['default_ind']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('default_ind',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#First split criterion used in Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Using Gini index (Default)-----------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     88258\n",
      "          1       0.99      0.89      0.94      8974\n",
      "\n",
      "avg / total       0.99      0.99      0.99     97232\n",
      "\n",
      "Confusion Matrix \n",
      " [[88179    79]\n",
      " [  961  8013]]\n",
      "The test accuracy is {:.3f} 0.9893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"----------Using Gini index (Default)-----------\")\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y_test,y_pred))\n",
    "acc_score=accuracy_score(y_test,y_pred)\n",
    "print(\"The test accuracy is {:.3f}\",round(acc_score,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData=pd.read_csv(\"TestData_CSM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.drop('issue_d',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=testData['default_ind']\n",
    "X=testData.drop('default_ind',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testData=rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Using Gini on Test Data-----------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.82      0.90    367646\n",
      "          1       0.03      0.91      0.06      2164\n",
      "\n",
      "avg / total       0.99      0.82      0.90    369810\n",
      "\n",
      "Confusion Matrix \n",
      " [[301105  66541]\n",
      " [   196   1968]]\n",
      "The test accuracy is {:.3f} 0.81954\n"
     ]
    }
   ],
   "source": [
    "print(\"----------Using Gini on Test Data-----------\")\n",
    "print(\"Classification Report:\\n\",classification_report(y,y_testData))\n",
    "print(\"Confusion Matrix \\n\",confusion_matrix(y, y_testData))\n",
    "acc_score=accuracy_score(y,y_testData)\n",
    "acc_score_test=accuracy_score(y,y_testData)\n",
    "print(\"The test accuracy is {:.3f}\",round(acc_score_test,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC Score</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Report</td>\n",
       "      <td>0.864217</td>\n",
       "      <td>0.028726</td>\n",
       "      <td>0.909427</td>\n",
       "      <td>0.819537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  ROC Score  Precision Score  Recall Score  \\\n",
       "0   Random Forest Report   0.864217         0.028726      0.909427   \n",
       "\n",
       "   Accuracy Score  \n",
       "0        0.819537  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "cols = ['Model', 'ROC Score', 'Precision Score', 'Recall Score','Accuracy Score']\n",
    "models_report = pd.DataFrame(columns = cols)\n",
    "tmp1 = pd.Series({'Model': \" Random Forest Report\",\n",
    "                 'ROC Score' : roc_auc_score(y,y_testData),\n",
    "                 'Precision Score': precision_score(y,y_testData),\n",
    "                 'Recall Score': recall_score(y,y_testData),\n",
    "                 'Accuracy Score': accuracy_score(y,y_testData)})\n",
    "model1_report = models_report.append(tmp1, ignore_index = True)\n",
    "model1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model tuning Begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=0, warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "print(rf.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model tuning on Gini index of TrainData.CSV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf={'max_depth':[3,4,5,6], 'min_samples_leaf':[0.03,0.04,0.05,0.06],'max_features':[0.2,0.4,0.6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf=GridSearchCV(estimator=rf,param_grid=params_rf,scoring='accuracy',cv=10,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv=grid_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'max_depth': 4, 'max_features': 0.6, 'min_samples_leaf': 0.03}\n"
     ]
    }
   ],
   "source": [
    "best_hyperparam=rf_cv.best_params_\n",
    "print(\"Best parameters :\",best_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score : 0.9433184119384872\n"
     ]
    }
   ],
   "source": [
    "best_cv_score=rf_cv.best_score_\n",
    "print(\"Best CV score :\",best_cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimators  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=4, max_features=0.6, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=0.03, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "best_model=rf_cv.best_estimator_\n",
    "print(\"The best estimators \",rf_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to compute accuracy on validation set\n",
    "test_accuracy=best_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy 0.9399168997860786\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy\",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on unseen data 0.9961385576377059\n"
     ]
    }
   ],
   "source": [
    "#Testing on training data\n",
    "testData_accuracy=best_model.score(X,y)\n",
    "print(\"Performance on unseen data\",testData_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
